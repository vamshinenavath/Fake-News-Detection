{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3871cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95538a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>junksci</td>\n",
       "      <td>First Certified Organic Fast Food Restaurant t...</td>\n",
       "      <td>by ARIANA MARISOL\\n\\nFast food restaurants are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reliable</td>\n",
       "      <td>UP polls: Parties say BJP setting agenda; vote...</td>\n",
       "      <td>India News UP polls: Parties say BJP setting a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hate</td>\n",
       "      <td>UCLA Student Is Charged With Attempted Murder ...</td>\n",
       "      <td>A UCLA student allegedly stabbed a classmate f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hate</td>\n",
       "      <td>National Vanguard</td>\n",
       "      <td>Transcript by Katana IT HAS NOW become absolut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>Truth Broadcast Network</td>\n",
       "      <td>448 Views0 Likes\\n\\nEurope has again been forc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fake</td>\n",
       "      <td>Meet China’s Morlocks: 1 Million Beijing Resid...</td>\n",
       "      <td>Meet China’s Morlocks: 1 Million Beijing Resid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>The Global Elite’s Digital Agenda Played Out a...</td>\n",
       "      <td>Susanne Posel, Contributor\\n\\nActivist Post\\n\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>political</td>\n",
       "      <td>Meet the 99.999999 Percent</td>\n",
       "      <td>Forget about the 1 percent versus the 99 perce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>satire</td>\n",
       "      <td>Isaiah Thomas praises LeBron James</td>\n",
       "      <td>Advertisements\\n\\nAdvertisements\\n\\nEven thoug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bias</td>\n",
       "      <td>Poetry’s Plum Gone to Hell</td>\n",
       "      <td>What is the use of writing about books?” asked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>A Theory On Jesse Ventura and Ron Paul., page 1</td>\n",
       "      <td>edit on 7-4-2011 by edgecrusher2199 because: L...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fake</td>\n",
       "      <td>Nuclear Alert: News Out Of NORTH KOREA… It Is BAD</td>\n",
       "      <td>As Reported By AFF\\n\\nNorth Korea’s nuclear te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>satire</td>\n",
       "      <td>Local Catholic Priests to Hold Traditional Boy...</td>\n",
       "      <td>Local Catholic Priests to Hold Traditional Boy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bias</td>\n",
       "      <td>О грудном молоке нужно позаботиться до беремен...</td>\n",
       "      <td>О грудном молоке нужно позаботиться до беремен...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>clickbait</td>\n",
       "      <td>Alt Right Archives</td>\n",
       "      <td>The Clinton campaign is so desperate to associ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>political</td>\n",
       "      <td>Germany reports ‘sharp rise’ in cyberattacks</td>\n",
       "      <td>Germany detected a sharp rise in cyberattacks ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>unreliable</td>\n",
       "      <td>Michael Carter Williams</td>\n",
       "      <td>Sports\\n\\nNBA Rumors: Bucks Determined To Trad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>unreliable</td>\n",
       "      <td>Cable: 1975STATE021023</td>\n",
       "      <td>Tor\\n\\nTor is an encrypted anonymising network...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>unreliable</td>\n",
       "      <td>Cable: 1975VIENNA04470</td>\n",
       "      <td>Tor\\n\\nTor is an encrypted anonymising network...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>satire</td>\n",
       "      <td>When You Are Ready To Have A Serious Conversat...</td>\n",
       "      <td>Larry Groznic\\n\\n\\n\\nI consider you a friend, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          type                                              title  \\\n",
       "0      junksci  First Certified Organic Fast Food Restaurant t...   \n",
       "1     reliable  UP polls: Parties say BJP setting agenda; vote...   \n",
       "2         hate  UCLA Student Is Charged With Attempted Murder ...   \n",
       "4         hate                                  National Vanguard   \n",
       "5   conspiracy                            Truth Broadcast Network   \n",
       "6         fake  Meet China’s Morlocks: 1 Million Beijing Resid...   \n",
       "7   conspiracy  The Global Elite’s Digital Agenda Played Out a...   \n",
       "8    political                         Meet the 99.999999 Percent   \n",
       "9       satire                 Isaiah Thomas praises LeBron James   \n",
       "10        bias                         Poetry’s Plum Gone to Hell   \n",
       "11  conspiracy    A Theory On Jesse Ventura and Ron Paul., page 1   \n",
       "12        fake  Nuclear Alert: News Out Of NORTH KOREA… It Is BAD   \n",
       "13      satire  Local Catholic Priests to Hold Traditional Boy...   \n",
       "14        bias  О грудном молоке нужно позаботиться до беремен...   \n",
       "15   clickbait                                 Alt Right Archives   \n",
       "16   political       Germany reports ‘sharp rise’ in cyberattacks   \n",
       "17  unreliable                            Michael Carter Williams   \n",
       "18  unreliable                             Cable: 1975STATE021023   \n",
       "19  unreliable                             Cable: 1975VIENNA04470   \n",
       "20      satire  When You Are Ready To Have A Serious Conversat...   \n",
       "\n",
       "                                              content  label  \n",
       "0   by ARIANA MARISOL\\n\\nFast food restaurants are...      1  \n",
       "1   India News UP polls: Parties say BJP setting a...      0  \n",
       "2   A UCLA student allegedly stabbed a classmate f...      1  \n",
       "4   Transcript by Katana IT HAS NOW become absolut...      1  \n",
       "5   448 Views0 Likes\\n\\nEurope has again been forc...      1  \n",
       "6   Meet China’s Morlocks: 1 Million Beijing Resid...      1  \n",
       "7   Susanne Posel, Contributor\\n\\nActivist Post\\n\\...      1  \n",
       "8   Forget about the 1 percent versus the 99 perce...      1  \n",
       "9   Advertisements\\n\\nAdvertisements\\n\\nEven thoug...      1  \n",
       "10  What is the use of writing about books?” asked...      1  \n",
       "11  edit on 7-4-2011 by edgecrusher2199 because: L...      1  \n",
       "12  As Reported By AFF\\n\\nNorth Korea’s nuclear te...      1  \n",
       "13  Local Catholic Priests to Hold Traditional Boy...      1  \n",
       "14  О грудном молоке нужно позаботиться до беремен...      1  \n",
       "15  The Clinton campaign is so desperate to associ...      1  \n",
       "16  Germany detected a sharp rise in cyberattacks ...      1  \n",
       "17  Sports\\n\\nNBA Rumors: Bucks Determined To Trad...      1  \n",
       "18  Tor\\n\\nTor is an encrypted anonymising network...      1  \n",
       "19  Tor\\n\\nTor is an encrypted anonymising network...      1  \n",
       "20  Larry Groznic\\n\\n\\n\\nI consider you a friend, ...      1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = \"datasets\"\n",
    "file = 'news_traindata' # 'WELFake_Dataset.csv'\n",
    "nrows = 50000\n",
    "vocab_file = f'vocabs/vokab_{file}_{nrows}.pkl'\n",
    "model_file = f\"models/stage1_model_{file}_{nrows}.pth\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(f'{dataset_dir}/{file}.csv', encoding='utf-8', nrows=nrows)\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc2133",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "##### Generating/loading Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80485e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary loaded from 'vocab.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "\n",
    "MAX_VOCAB = 25000\n",
    "special_tokens = ['<unk>', '<pad>']\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def generate_vocabulary(df):\n",
    "    counter = Counter()\n",
    "    for text in df['content']:\n",
    "        if pd.notna(text):\n",
    "            counter.update(tokenizer(str(text)))\n",
    "    \n",
    "    most_common = [token for token, _ in counter.most_common(MAX_VOCAB - len(special_tokens))]\n",
    "    \n",
    "    vocab = build_vocab_from_iterator([most_common], specials=special_tokens)\n",
    "    vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "    with open(vocab_file, 'wb') as f:\n",
    "        pickle.dump(vocab, f)\n",
    "    print(f\"Vocabulary saved to '{vocab_file}'.\")\n",
    "\n",
    "    return vocab\n",
    "\n",
    "\n",
    "if os.path.exists(vocab_file):\n",
    "    with open(vocab_file, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    print(f\"Vocabulary loaded from {vocab_file}.\")\n",
    "\n",
    "else:\n",
    "    vocab = generate_vocabulary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d5963",
   "metadata": {},
   "source": [
    "##### Encoding the Content and label with vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30c9ac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered texts: 48252, Labels: 48252\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "MAX_LENGTH = 2048\n",
    "\n",
    "encoded_texts_and_labels = []\n",
    "for text, label in zip(df['content'], df['label']):\n",
    "    if pd.notna(text):\n",
    "        # Tokenize and encode in one step with list comprehension\n",
    "        encoded = [vocab[token] for token in tokenizer(text)]\n",
    "        \n",
    "        if len(encoded) <= MAX_LENGTH:  # Filter long sequences\n",
    "            encoded_texts_and_labels.append((torch.tensor(encoded, dtype=torch.long), label))\n",
    "\n",
    "\n",
    "# Separate encoded texts and labels\n",
    "encoded_texts = [item[0] for item in encoded_texts_and_labels]\n",
    "labels = torch.tensor([item[1] for item in encoded_texts_and_labels], dtype=torch.float)\n",
    "\n",
    "# Pad sequences\n",
    "padded_texts = pad_sequence(encoded_texts, batch_first=True, padding_value=vocab['<pad>'])\n",
    "\n",
    "print(f\"Filtered texts: {len(padded_texts)}, Labels: {len(labels)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f20e2",
   "metadata": {},
   "source": [
    "##### Creating DataLoader from test-train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "735fae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(padded_texts, labels, test_size=0.1)\n",
    "\n",
    "train_ds = NewsDataset(X_train, y_train)\n",
    "val_ds = NewsDataset(X_val, y_val)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, pin_memory=True, num_workers=0)\n",
    "val_dl = DataLoader(val_ds, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e6490f",
   "metadata": {},
   "source": [
    "## Training The Model\n",
    "\n",
    "##### Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee313013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "done constructing model\n",
      "done constructing optimizer\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1221, Val Acc: 0.9728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     acc = evaluate(model, val_dl)\n\u001b[32m     50\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, loader)\u001b[39m\n\u001b[32m     26\u001b[39m preds = model(xb)\n\u001b[32m     27\u001b[39m loss = criterion(preds, yb)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m optimizer.step()\n\u001b[32m     30\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cs240env/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    514\u001b[39m         Tensor.backward,\n\u001b[32m    515\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    520\u001b[39m         inputs=inputs,\n\u001b[32m    521\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cs240env/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    261\u001b[39m     retain_graph = create_graph\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from mulstage_model import CNN_BiLSTM\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = CNN_BiLSTM(vocab=vocab, vocab_size=len(vocab), embed_dim=100, hidden_dim=128, output_dim=1, pad_idx=vocab['<pad>'])\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff18181a",
   "metadata": {},
   "source": [
    "##### train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0308d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            preds_class = (preds > 0.5).float()\n",
    "            total_acc += (preds_class == yb).float().mean().item()\n",
    "    return total_acc / len(loader)\n",
    "\n",
    "print(\"training\")\n",
    "\n",
    "for epoch in range(5):\n",
    "    loss = train(model, train_dl)\n",
    "    acc = evaluate(model, val_dl)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}, Val Acc: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5fa703",
   "metadata": {},
   "source": [
    "##### saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7054c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585fce6b",
   "metadata": {},
   "source": [
    "### Test the model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8bbce56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9755\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_acc = evaluate(model, val_dl)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs240env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
